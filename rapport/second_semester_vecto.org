#+TITLE: Rapport Second Semestre pour le support de la Vectorisation
#+AUTHOR: Sholde
#+DATE: 2021

* Introduction

  Ce rapport fait suite au précédent. Les informations rédigé sur le prédécent
  rapport doivent donc être comprisent afin de pouvoir comprendre la suite du
  rapport.

  Les sources sont toujours disponnible sur notre Organisation github:
  https://github.com/Safecarlo

  Notement les sources pour le support de la vectorisation qui se trouvent sur
  la branche vectorisation de notre fork:
  https://github.com/Safecarlo/verificarlo/tree/vectorization

  Un autre répertoire important est celui du benchmark que nous avons utiliser
  pour évaluer l'efficacité de notre implémentation vectorielle:
  https://github.com/Safecarlo/benchmark

* Support de la vectorisation
** Point git
*** Rebasage
    
    Durant le semestre, des modifications ont été apporté sur la branche master
    de *verificarlo*. Pour ne pas être trop éloigner de la version scalaire de
    cette branche nous avons donc décidé de rappatrier les modifications sur
    notre branches master de notre fork.

    Le problème étant que nous avons utilisé la stratégie par fusion (qui était
    par défault) au lieu de faire un rebasage afin de grouper les modifications
    (commits) au lieu de les éparpiller.

*** Pull requests sur verificarlo

    Des pull requests ont été fait sur verificarlo, notamment pour nettoyer le
    répertoire de tests qui n'était pas nétoyer par la cible "clean" du
    makefile. Comme verificarlo utilise les *autotools*, la cible n'est pas
    directement disponnible et nous avons du utiliser une dépendence de la cible
    "clean" des *autotools* qui est "clean-local". Et avec cette cible nous
    appelons notre cible en la mettant comme dépendance de la cible
    "clean-local" qui nettoye le répertoire ~tests/~.

    Nous avons fait cette PR (pull requests) car nous développions des tests
    dans verificarlo afin de s'assurer que nos changement dans le code soit
    bon. Le problème était que de multiple fichiers était créés mais j'avais
    supprimés. Et cela était un peu embêtant lorsque nous voulions lister nos
    fichier (avec la commadne ls) ou bien utiliser un script car les anciens
    résultat n'était pas éffacé (enfin on les enlevé manuellement au début puis
    nous avons vite arrêté). De plus il y avait 2 fichier qui était créer à la
    configuration de verificarlo dans le répertoire qui n'était pas non plus
    nettoyé.

    Tous ces fichier non nettoyais nous embêter pour utiliser git car comme nous
    éditions aussi d'autre fichier nous avions les 2 fichiers créer par la
    configuration à chaque fois.
    
** Mise à jour du backend *ieee*
*** Ajout du compte des opérations flottantes vectorielles dans le backend *ieee*

   Lors de le mise à jours de notre branche master, nous nous sommes rendu
   comptes que des changements ont été apportés au backend *ieee*. Notemmant
   celle du comptage des opérations. Cependant le comptage des opérations
   flottante de comptait que les opérations scalaire comme ci-dessous:

   #+BEGIN_SRC shell
operations count:
     mul = 1 total count;
     div = 0 total count;
     add = 0 total count;
     sub = 0 total count;
   #+END_SRC

   Nous avons donc ajouter le compte spécifiques de chaque opérations
   vectorielles et décidé d'afficher un pourcentage de vectorisation.

   #+BEGIN_SRC shell
operations count:
     mul = 1 total count; 100.00% vectorized;
     div = 0 total count;   0.00% vectorized;
     add = 0 total count;   0.00% vectorized;
     sub = 0 total count;   0.00% vectorized;
   #+END_SRC

   Cependant, l'affichage ne nous semblait pas suffisant car nous avions
   l'information du nombre de chaque opérations flottantes par taille mais nous
   ne l'utilisions pas. Nous avonc donc rajouté le pourcentage pour chaque
   taille de vecteur.

   #+BEGIN_SRC shell
operations count:
     mul = 1 total count; 100.00% vectorized;   0.00% 2x; 100.00% 4x;   0.00% 8x;   0.00% 16x
     div = 0 total count;   0.00% vectorized;   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
     add = 0 total count;   0.00% vectorized;   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
     sub = 0 total count;   0.00% vectorized;   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
   #+END_SRC

   Comme vous pouvez le constatez, la ligne afficher est très grandes, et il
   arrive que l'on veuille séparer notre écran en 2 (pour x ou y raison) et que
   l'affichage est environ restreint à 80 caractères. C'est pourquoi nous avons
   fait un affichage en 2 lignes:

   #+BEGIN_SRC shell
operations count:
     mul = 1 total count; 100.00% vectorized;
           by size:   0.00% 2x; 100.00% 4x;   0.00% 8x;   0.00% 16x
     div = 0 total count;   0.00% vectorized;
           by size:   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
     add = 0 total count;   0.00% vectorized;
           by size:   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
     sub = 0 total count;   0.00% vectorized;
           by size:   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
   #+END_SRC

   Le problème avec cette dernière version est qu'elle est moins lisible que
   la précédente où toutes les informations sont alignés.
   
*** Tests

    Nous avons aussi ajouté des tests plus approfondie pour ce backend avec des
    nombres aléatoirement choisis de sorte à avoir des nombres négatif, des
    nombres avec un exposant négatif ou bien même des nombre avec un exposant
    positif afin de s'assurer que l'implémentation fonctionne.
    
** Vectorisation du backend *vprec*

   Ce backend permet de gérer les cas des nombres spéciaux comme les nombres
   *dénormaux* et les nombres *infinis*. Cepandant ces cas restent rares dans les
   codes de calculs. C'est pourquoi nous avons décidé de priorisé la
   vectorisation pour les cas des nombres *normaux*.

*** Petit rappel des cas spéciaux

    Prenons comme exemple une précision de 3 et une porté de 2 pour un type
    flottant simple précision (donc nous avons 1 bit de signe, 2 bit d'exposant
    et 3 bit de pseudo-mantisse). Prenons [[stdieee][la formule du standart *IEEE*]] qui est:
    (-1)^S * 2^(E - (2^(e - 1) - 1)) * (1 + P / 2^p)
    - *plus petit normal:* 0
    - *plus grand normal:* 1,75 (2^1 * (7 / 8))
    - *plus petit dénormal:* 0,125
    - *plus grand dénormal:* 0,875
    - *infini*: nombre supérieur à 1,75 ou inférieur à 0,125

    Voir la [[figure 1][figure 1]].
   
*** Tests

    Tout d'abord comme pour le premier semestre nous avons ajouté des tests pour
    tester notre implémentations vectorielles des opérations vectorielles. Nous
    avons choisis de faire des tests simple c'est pourquoi nous avons modifié
    le test *tests_vprec_backend_simple*.

    Pour ce faire nous avons "copié/collé" les input scalaires car nous étions
    sûr que c'est input fonctionne. Notre code prends donc 2 line d'entrée car il
    ne test que les vecteurs de taille 2 (c'est pourquoi il prends 2 ligne
    d'entrée). La première ligne correspond au premier élément de chaque vecteur
    d'entrée (a et b), et la deuxième ligne le deuxième élement de chaque
    vecteur. Il garde ainsi les mêmes opérations que pour les sacalaires ce qui
    peut facilité le changement d'un calcul si jamais il s'avère qu'il y en est
    un qui soit mauvais.

    Cependant le test ne test que la multiplication. Mais nous testons pour les
    2 formats floattans du *C*, le format *simple précision* et le format
    *double précision*.

    Ici nous n'avons pas vraiment besoin de tester les autres tailles ainsi que
    les autres opérateurs car nous avions fait au premier semestre un test qui
    le faisait, certes simple mais il le faisait. De plus nous avons ajouter les
    tests pour les nombres normaux mais pas pour les nombres infini car nous
    avions un problème avec le retour du script qui calcul avec la librairie
    *mpfr*.
    
*** Stuctures

    Tout d'abord nous avons remarqué que le backend utilise des structures pour
    faciliter la compréhension des calculs. Or les structures comportent des
    types scalaires. Il faut donc créer de nouvelles structures pour les types
    vectorielles que propose *clang*.

**** Code de la version scalaire pour les flottants

#+BEGIN_SRC c
typedef union {

  float f32;
  uint32_t u32;
  int32_t s32;

  /* Generic fields */
  float type;
  uint32_t u;

  struct {
#if __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__
    uint32_t sign : FLOAT_SIGN_SIZE;
    uint32_t exponent : FLOAT_EXP_SIZE;
    uint32_t mantissa : FLOAT_PMAN_SIZE;
#endif
#if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__
    uint32_t mantissa : FLOAT_PMAN_SIZE;
    uint32_t exponent : FLOAT_EXP_SIZE;
    uint32_t sign : FLOAT_SIGN_SIZE;
#endif
  } ieee;

} binary32;
#+END_SRC

**** Pour la version vectorielles

      Comme nous ne pouvons pas faire des conditions de *preprocessing* dans les
      *macros* nous avons englobé nos *macros* dans les conditions de
      *preprocessing* afin de pouvoir définir les structures pour toutes les
      tailles de vecteur.

*** Types vectorielles

    Cependant au cours de l'écriture des structures vectorielles nous nous somme
    rendu compte qu'il nous fallais des vecteurs d'entiers signés de 64 bits
    pour les types flottants de 64 bits.

    C'est pourquoi nous les avons rajouté et que nous avons créer un fichier
    nommé *float_type.h* pour regroupé toutes les définitions des types
    vectorielles pour éviter de les redéfinir dans chaque fichier.

    Cependant nous n'avons pas réussis à introduire se fichier dans les
    *include* des wrappers. C'est pourquoi nous avons redéfini les types dans le
    fichier *interflop.h* car il est inclu dans le fichier final des wrappers.

*** Fonctions

    Il nous restait à vectoriser les fonctions du backends.

    Pour ce qui est des fonctions, elles utilisent elles aussi des types
    scalaires. Il faut donc créer des fonctions utilisant les types vectorielles.

**** Fonction principale

     Comme nous passons la taille du vecteur en paramètre il faut donc que l'on
     appelle la bonne fonction suivant la taille du vecteur. Le plus optimial
     dans notre cas était d'englober tout le code pour la même taille de vecteur
     afin de ne pas a devoir la retester par la suite.

     Pour ce qu'il est du calcul de l'opération originale, c'est le même procédé
     que pour le backend *ieee*.

**** Gestion des arrondis

    Ici commence la vectorisation du bakend.

    Comme dit dans le préambule un nombre flottant peut être dans 3 catégories:
    normal, dénormal et infini. Etant donné que les 2 derniers cas restent des
    cas rares dans les codes de calculs. Nous avons décidé de vectoriser que le
    cas des nombres flottants normal.

    Mais pour pouvoir vectoriser il faut que tous les éléments de vecteurs aient
    le même comportement. C'est pourquoi on parcours une fois le vecteur élément
    par élément pour s'assurer que tout les éléments soit des nombres normaux.

    Si il s'avère qu'il y ai 1 nombre dénormal et 7 nombres normaux dans un
    vecteur de 8 flottants simple précision. Alors on reparcours le vecteurs
    pour gérer les 7 nombres normaux qui n'ont pas encore été traités.

    ici exemple cas 1 dénormal et 7 normal
    ici exemple cas full normal

    _Complexité en terme d'accès aux éléments:_
    - cas *size* nombres infini : O(n)
    - cas *size* nombres dénormal : O(n)
    - cas *size* nombres normal : O(n)
    - mélange de *normal* avec *infini* ou *dénormal* : O(2n)

    Dans le code nous voyons que l'on utilise 2 fonctions pour gérer le cas des
    nombres normaux, une avec la calcul d'une erreur absolue et l'autre sans. Il
    faut donc vectoriser ces 2 fonctions.

**** Cas des nombres normaux
***** Cas des nombres normaux

     Pour vectoriser la fonction qui calcul les arrondis pour les nombres normaux
     il suffisait d'utiliser les opérations avec des types vectorielles de *clang*.

***** Cas des nombres normaux avec erreurs absolue

    Ici aussi on a opté pour la même technique de vectorisation. Comme on ne
    peut vectoriser le calcul que si tout les éléments du vecteurs ont le même
    comportement, on a choisis de vectoriser lorsque l'on se trouve dans le cas
    où tout le vecteur contient des nombres normaux. Car c'est le cas le plus fréquents.

    On parcours la aussi le vecteur élément par élément pour savoir si un
    élément du vecteur est en dessous de l'erreur absolue fixé. Si aucun élément
    n'est en dessous alors ils sont tous normaux et on peut vectoriser. Sinon on
    re-parcours le vecteur pour calculer les éléments normaux restant.

    _Complexité en terme d'accès aux éléments:_
    - cas *0* ou *size* éléments en dessous de la valeur absolue fixé : O(n)
    - cas entre *1* et *size - 1* éléments en dessous de la valeur absolue fixé :
      O(2n)

** Benchmark
*** Explication
**** But
     
     Le but du *benchmark* est de tester les performances de notre implémentation
     vectorielles en les comparant avec la version scalaire. Seul le format
     simple précision est testé ainsi que les tailes de vecteur pour *SSE* et
     *AVX* donc les vecteurs de 2, 4 et 8 simple précision. Nous n'avons pas mis
     le vecteur de 16 simple précision car très peu de processeur le possède et
     cela nous ferai une case vide pour nos plot si on gardait les mêmes
     scripts. Pour ce qui est des doubles précisions, c'est aussi pour des
     raisons de script car le vecteur de 16 double précision n'existe pas
     vraiment et donc il n'y a que 3 taille de vecteur, contrairement au simple
     précision qui en a 4.

**** Backend testé
     
     Le benchmark test les backends *ieee* et *vprec*, qui pour ce dernier test
     le cas où l'opération donne un vecteur avec uniquement des nombres normaux
     car c'est le cas que nous avons vectorisé et le cas où l'opération donne un
     vecteur contenant uniquement des nombres dénormaux, qui est un cas non
     vectorisés. Et nous utilisons le mode par défaut où uniquement le vecteur
     final est traité spécifiquement par le backend *vprec*.

**** Avant de faire les mesures de performances
     
     Nous avons utiliser ce que nous avons appris au premier semestre dans le
     cours d'Architecture Parallèle pour mesurer les performances. C'est à dire
     que nous avons changer le gouverneur du processeur en espace utilisateur
     pour pouvoir affecter la fréquence maximum de notre processeur (sauf pour la
     machine virtuel ou nous ne pouvons pas mais elle est ici car sur
     l'ordinateur portable nous n'avons pas *AVX*). De plus nous avons affecter
     notre programme au dernier coeur de notre processeur pour l'éloigner le plus
     possible du coeur 0 qui est le coeur privilégier du système d'exploitation.

**** Métriques

     Nous avons aussi vu les métriques à prendre en compte, comme le temps que
     prend notre micro-benchmark. Mais pour s'assurer que le temps ne soit pas
     faussé il faut calculer la écart type qui indique l'écart moyen
     entre chaque échantillon. Il nous faut donc aussi plusieurs échantillons
     / executions du micro-benchmark à évaluer. Pour ce qui est du seuil de
     validation, il est un peu arbitraire. Il faudrai voir selon notre benchmark
     quelle est le seuil pour lequel on peut dire que la mesure n'est pas faussé
     mais nous n'avons pas vraiment pris le temps de le faire. Donc le seuil de
     6% est plus la à titre représentatif.

**** Sauvegarde des résultats bruts
     
     Nous avons aussi appris qu'il fallait gardé les résultats brut afin de
     pouvoir comparer avec une autre machine, chose que nous faisons.

**** Résultat espérer
 
     Les résultats espérer avec notre implémentation est à peut près la moitier
     du maximum possible car beaucoup d'appel de fonction sont fait ainsi que de
     condition.

**** Explication du calcul des métriques
***** Définitions des micro benchmark

      Les micro-benchmark sont les boucles qui font le calcul que l'on mesure,
      comme l'addition, la soustraction, la multiplication et la division.
      
***** Nombres d'exécutions des micro-benchmark

      Le nombre d'exécution des micro-benchmark est choisis arbitrairement. Il
      nous a paru que 30 était suffisant pour évaluer si les mesures était
      faussé ou non.
      
***** Nombres d'opérations

      Le nombre d'opération à été choisis abritrairement de façon à mesurer un
      temps de calcul raisonnable pour ne pas faussé les mesures de temps de
      chaque exécution des micro-benchmark.

      Ici nous avons choisis 1.000.000 d'opérations globales, soit 1 MFLOP.

      Pour ce qui est du nombre d'opération pour un vecteur de 1 simple
      précision, cela ne change pas, il est de 1 MFLOP.

      Par contre, pour les vecteurs de 2, 4 et 8 simple précision nous divison
      bien évidement par ce nombre le nombre d'opération global. C'est-à-dire
      que pour un vecteur de 2 nous ferons 500.000 opérations avec des vecteurs
      de 2 simple précision ce qui nous amène au final à faire 1 MFLOP.

      Nous n'avons pas de soucis de décomposition car le nombre global
      d'opération est assez grand pour que la division entière donne un nombre
      entier d'opérations vectorielles.

***** Temps

      Si le temps est faussé, c'est-à-dire que l'on a eu un overflow de
      l'horloge et donc que le temps de fin est inférieur au temps de départ
      alors on répète l'exécution.

      Si le temps est bon alors on le stocke dans un tableau qui contiendra les
      temps de chaque exécution.

      Les temps sont calculé en nano-secondes pour plus de précisions et son
      rammené en seconde en multipliant par 1.000.000 (10e^9).

      Une fois les temps calculés nous calculons la moyenne de ces temps afin de
      fournir à l'utilisateur le temps moyens au lieu d'un temps bruts pour
      évité de faussé les mesures.
      
***** Ecart type

      L'écart type est calculé comme dans so formule mathématique c'est à dire
      la racine carré de la variance. C'est-à-dire la différence au carré de
      chaque temps moins le temps moyens, divisé par le nombre de l'échantillon,
      le tout dans une racine carré.

      stddev = sqrt(var) = sqrt((sum((x - m)^2)) / n)
      
***** Speedup

      Les speedups calculés corespondent pour la première barre le speedup de la
      *version sérial* d'une opération vectorielle par rapport à l'opération
      scalaire. Pour la deuxième barre le speedup de la *vesion vectorielle* d'une
      opération vectorielle par rapport à l'opération scalaire. Et pour la
      dernière barre le speedup de la *version vectorielle* par rapport à la
      *version sériale* pour la même taille de vecteur.
    
*** Résultat
**** Ecart type
     
     Bien que nous utilisions une machine virtuelle, nous pouvons voir que les
     résultats sont assez stable exepté 1 ou 2 fois. (voir les figures [[figure 3][3]], [[figure 5][5]] et [[figure 6][6]])

**** Backend IEEE

     Pour ce qui concerne le backend *ieee* (voir la figure [[figure 2][2]]),nous avons un
     speedup d'environ de la moitier du maximum possible et les résultats sont
     assez semblable suivant le type d'opération.

**** Backend VPREC

     Pour ce qui concerne le backend *vprec* (voir la figure [[figure 4][4]]), nous pouvons
     constater que pour une opération où le vecteur final contient que des
     nombres normaux va beaucoup plus vite à être calculer qu'une opération où le
     vecteur final contient uniquement des nombres dénormaux. Ce qui est normal
     car dans le cas où le vecteur final ne contient que des nombres normaux le
     calcul est vectorisé.

**** Conclusion

     La différence est flagrante mais le calcul des nombres dénormaux va plus
     vite sur notre branche. On peut se demander si le fait de faire moins
     d'appel de fonction joue donc un grand rôle sur le gain de notre
     implémentation. C'est pourquoi nous avons fait une version sérialisé ou on
     appelle les fonctions qui s'occupe des nombres normaux à partir de notre
     implémentation pour voir les performances.

     Nous avons donc mesurer les performances pour cette nouvelle implémentation
     et l'avons comparé avec la vesrion vectorisé sur le même graphique afin de
     voir la proportion que prend la réduction des appels dans le gain de temps
     et on peut dire qu'elle prend environ 1/4 du gain. Donc le gain pur pour la
     vectorisation est en fait de 3/4 du gain.

     Nous pouvons donc constater que le gain apporté avec notre implémentation
     est d'environ la moitié de ce que l'on peut espérer en vectorisant des
     opérations. Il est donc possible de faire une implémentation plus efficace
     qui sera détaillé dans la conclusion de la vectorisation.

** Mise au point sur le non support des tailles de vecteurs plus grandes que celles supportés
** Conclusion de la vectorisation
* Support de la parallélisation

** Introduction

  Avant de commencer avec les benchmark NAS parallèle avec un peut d’historique .
  Les benchmarks traditionnels existant bien avant les NPB étaient généralement limités
  pour être spécialisé pour les ordinateurs vectoriels.Du coup malgré leurs capacités ils ont toujours des
  insuffisances divers empêchant le parallélisme , et aussi des problèmes de
  tailles et capacités insuffisante , ce qui les rendait inappropriés pour les
  systèmes purement parallèles,donc cela est considéré comme problème de manque de performances.
  Par conséquent, les NPB ont été développés afin de remédier au manque à ce manque de performances ainsi que les
  insuffisances dans les machines hautement parallèles.
  
** Définition NAS Benchmarks parallèle

  Les NAS parallèle benchmarks (NPB) sont été développés au centre de la recherche de la NASA. Ce sont une suite de 
  benchmarks améliorées afin d’augmenter et d’améliorer les performances informatique parallèles qui est faible 
  dans les benchmarks traditionnels. Pour definir les NAS, c'est un outil développés et améliorer pour évaluer 
  la perfomances des supers calculateurs.
  
** Evolution des NAS Benchmarks Parallèle

  Comme tous les outils et programmes, le NPB pendant son évolution et
  développement est passé par plusieurs phase et plusieurs versions amélioré
  avec le temps et dépendant des besoins et problème rencontrés ; pour cela
  dans ce qui suit on a détaillé les trois version du NPB , tel que chaque
  spécification a des référence plus améliorées par rapport à l’ancienne
  version.
  
*** La version NPB1:
  
  Cette version est la première version appliquée, ces spécifications sont implémentées en utilisant des algorithmes et des
  modèles de programmation adaptés à leurs différentes machines.Dans cette version, ils ont utilises des algorithmes 
  spécifier pour l’ensemble des problèmes rencontrés a des points de référence qui puissent assurer :
  
   -l’implémentation de nouveau algorithmes et fonctions compatibles au parallélisme
   - vérification de la performance ainsi que l’exactitude des résultats retournés par l’exécution
   -Faciliter de travailler et de s’adapter avec les systèmes multicœurs fiable ,ainsi que la facilité de la distribution
  et communication multicœurs.
  
*** La version NPB2:
  
  Après avoir utilisé la version NPB1 , des problèmes de performances ainsi que du parallélisme sont résolus, 
  d’un autre coté des problèmes et faiblesses nouveaux sont rencontrés. La majorité des implémentations NPB 
  n’ont pas entaient a la porté du grand public qui veut travailler dessus, en cachant leurs techniques d’optimisations 
  sur ce dernier.ainsi que vu l’évolution des supercalculateur,l’implémentation du NPB1 a un retard et évolue pas avec 
  ces derniers, c’est pour cela ils ont optes pour la version NPB2 afin d’améliorer et de régler ses soucis rencontrés 
  en apportant des implémentation de codes sources pour les benchmark 
  implémentés dans NPB1.donc la spécification NPB2 complète les spécifications du NPB1 et nous a permis :
  -modifier les règles de soumise des résultats de l’analyse comparative
  - Disponibilité des fichiers source et des scripts des construction afin d’assurer la disponibilité publique des 
  modification des résultats.
  - Et enfin la version NPB2 a permis d’être implémenter des codes basé sur MPI .
  
***  La version NPB3:
 
  Après l’apparition et l’implémentation de la version NPB2 MPI; la version NPB3 est apparue et a conservé l’implémentation
  dans MPI vue en NPB2 et a effectué des améliorations afin d’être implémenté dans OpenMP.
  Mais en plus de ça des implémentations qui étais en série dans NPB2 , sont amélioré afin d’être en parallèle avec des 
  optimisations supplémentaire. Ainsi que NPB3 a rajouté de nouvelle références tel que : l’ajout d’outils
  de parallélisation multi-niveau et hybrides.et aussi un ensemble de benchmarks multi-zone un ensemble de benchmarks multi-zone tirant parti
  du modèle de programmation hybride MPI / OpenMP a été publié pour tester l'efficacité des paradigmes ,ainsi que l’allocation de mémoire
  dynamique.

** Spécification des références
 
  Ils existent plusieurs types de benchmark dont on va citer après. Les types des benchmarks sont différent 
  d’une version à une autre , chaque version a ses propres spécifications.
  
**** Cinq noyaux :
  
  -IS : Il consiste le tri d’entiers et l’accès en mémoire aléatoire.
  
  -EP : embrassement parallèle : dans le calcul parallèle, une charge de
        travail où un problème est parallèlement embarrassant ou parfaitement
        parallèle est celui ou peu d’effort est nécessaire pour séparer le problème
        en un certain nombre de taches parallèles.
        
  -CG : gradient conjugué , veut dire l’accès irrégulier à la mémoire .
  
  -MG : multi-grille ,sur une séquence de maillage , la communication
        courte et longue distance. Donc L'idée principale du multi grille est
         d'accélérer la convergence d'une méthode itérative de base.
         
   -FT : Transformé de fourrier permet de résoudre les équations
         différentielles partielles en 3D et communication tous à tous.
          
**** Trois pseudos applications :
   
    Ils existe 3 types de pseudo application pour le NPB:
    - solveur tri_diagonale de blocs (BT) 
    
    - solveur scalaire pentadiagonale (SP)
    
    - solveur Gauss Seidel inférieur ou supérieur(LU)
    
**** Classes de référence pour le NPB:
   
   Ils existent plusieurs classes pour NPB,et que chaque classe a ces propres caractéristiques.
   - Classes A , B , C utilisées pour les problèmes de tests standards.
   - Classes D , E , F utilisée pour les gros problèmes de tests 
   - Classe S pour des tests rapides .
   
** Résultats et discussion
  
  Pour les tests, vu que nos machine ne supporte pas les tailles pour les tests standard et gros problème,
  donc on est reste sur la classe "S". Ici on a utilise comme compilateur la nouvelle version de verificarlo,
  c'est à dire la version vectorisé.
  Comme example on va prendre le benchmark BT et de classe S. Pour pouvoir execute le benchmark, il nous
  demande un nombre de coeur qui répresente le carré d'un nombre. La figure suivant répresente le résume 
  du compilation du benchmark BT:
  
   <<figure a>>
   #+CAPTION: Rappel des cas spéciaux
   #+NAME: fig:Résume BT benchmark
   #+ATTR_LATEX: :width 500px
   [[../ressources/btcompleted.png]]
   
   Après avoir compile et éxecuté le benchmarck bt, la vectorisation au niveau du programme est répresenter
   dans la figure suivante:
   
    <<figure b>>
   #+CAPTION: Vectorisation au niveau du benckmark BT
   #+NAME: fig:Résume BT benchmark
   #+ATTR_LATEX: :width 500px
   [[../ressources/vect1.png]]
   
   Le bechmarck que nous avons testé est ecrit avec le langage fotran et parallèlisé avec MPI. Du coup on peut constaté
   sur la figure que le niveau de véctorisation est null. Celle-ci peut être dû à la difference de syntax de langage entre
   le langage C et fortran. 
   Pour bien observer le niveau de véctorisation sur le benchmark BT, on a récuperé une source de benchmark qui est écrit avec
   le langace C et parallèliser avec openmp.
   Les figures suivantes répresenter l'évaluation des véctorisations au niveau du benchmark BT avec 8 threads:
   <<figure c>>
   #+CAPTION: Vectorisation au niveau u benckmark BT
   #+NAME: fig:Résume BT benchmark
   #+ATTR_LATEX: :width 500px
   [[../ressources/vcopenmp.png]]
   
* Conclusion

  Le test que nous avons fait à montrer que les opérations vont plus vite avec la véctorisation. A cause de manque de ressource 
  sur nos machine, on a été obligé de se limité à des tests minimun. Mais ce qui serai été intéressant c'est de pouvoir faire 
  des tests sur des supércalculateurs avec les différents classe de benchmark et de bien évaluer la pérformance de la machine ainsi
  que d'observer les niveaux de véctorisation sur une grande taille de calcul.
  
* Référence

  <<stdieee>>
  - Aide Mémoire sur le standart IEEE754, Pablo de Oliveira Castro,
    https://sifflez.org/lectures/archi-ord/AideMemoireIEEE754.pdf
  - Extension des vecteurs de Clang, Clang / LLVM,
    https://clang.llvm.org/docs/LanguageExtensions.html#vectors-and-extended-vectors
   - NAS Parallel Benchmark
      https://www.nas.nasa.gov/publications/npb.html
      https://github.com/benchmark-subsetting/NPB3.0-omp-C

* Annexe
** Rappel des cas spéciaux

    <<figure 1>>
   #+CAPTION: Rappel des cas spéciaux
   #+NAME: fig:rappel_des_cas_speciaux
   #+ATTR_LATEX: :width 500px
   [[../ressources/special_case.png]]

** Résultat
*** Sur une machine virtuel

    <<figure 2>>
    #+CAPTION: Résultat du backend IEEE
    #+NAME: fig:res_vm_ieee
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_ieee.png]]

    <<figure 3>>
    #+CAPTION: Dérivation standart du backend IEEE
    #+NAME: fig:stddev_vm_ieee
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_ieee_stddev.png]]

    <<figure 4>>
    #+CAPTION: Résultat du backend VPREC
    #+NAME: fig:res_vm_vprec
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_vprec.png]]

    <<figure 5>>
    #+CAPTION: Dérivation standart du backend VPREC avec des nombres normaux
    #+NAME: fig:stddev_vm_vprec_normal_stddev
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_vprec_normal_stddev.png]]

    <<figure 6>>
    #+CAPTION: Dérivation standart du backend VPREC avec des nombres dénormaux
    #+NAME: fig:stddev_vm_vprec_denormal_stddev
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_vprec_denormal_stddev.png]]

    <<figure 7>>
    #+CAPTION: Résultat du backend VPREC entre l'implémentaion sérial et l'implémentation vectorielle des nombres normaux
    #+NAME: fig:res_vm_vprec_vs
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_vprec_serial_vs_vector.png]]

